---
title: "An Introduction to the No U Turn Sampler and dual averaging"
author: "Henri Funk"
date: "3 12 2020"
output:
  revealjs::revealjs_presentation:
    self_contained: false
    theme: simple
    reveal_plugins: ["zoom", "menu", "notes"]
    center: false
    css: styles.css
    highlight: "zenburn"
    transition: "none"
    fig_caption: yes
    reveal_options:
      slideNumber: true
header-includes:
  - \usepackage{diffcoeff,amssymb}
bibliography: references.bib
vertical-center : true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::load_all()
```

# {data-background=#262626}

<h1 style="color: #fff">Metropolis(-Hastings) Algorithm</h1>

<center>
```{r, echo=FALSE}
knitr::include_graphics("files/MH.png")
```
</center>


## Random Walk

> * proposal in MH is sampled randomly from porpoals/jumping distrib $J_t(\theta_a|\theta_b)$

> * the accpetance rule/ transition function ratio of densities guarantees convergence

<div class="fragment">
$$
\begin{aligned}
T_t(\theta^t|\theta^{t-1}) = \frac{\frac{p(\theta^*|y)}{J(\theta^*|\theta^{t-1})}}{\frac{p(\theta^{t-1}|y)}{J(\theta^{t-1}|\theta^*)}}
\end{aligned}
$$
</div>

> * *But* if steps are poorly chosen converges speed, and accordingly, computational effort can get high

<div class="fragment">
$J(\cdot)$ is only useful jumping distibution, if:

* For any $\theta$ it is easy to sample from $J(\theta_a|\theta_b)$

* It is easy to compute r (e.g. if proposal is symmetric)

* The jump has a *reasonable* distance

* We don't reject/ accept jumps to often
 (see @gelman13)
</div>


## Problem

```{r, echo=FALSE, out.width='75%'}
knitr::include_graphics("files/HMC_multimodal.gif")
```
@feng20

* Gibbs and MH spend a lot of time zigging and zagging in the target distribution
* For models in High-D parameter-space reparametrization  and efficient jumping rules might fail

## Idea

> * Introduce a momentum $\phi_j$ for each component $\theta_j$
> * update $\theta\ \& \ \phi$ simultaneously
> * Let the jumping distribution $J(\cdot)$ be largely determined by $\phi$

<div class="fragment">
$\rightarrow$ the resulting algorithm is somewhat a *hybrid* Monte Carlo with a
mix of the known random walk and deterministic simulation methods derived from hamiltonian dynamics
</div>

# {data-background=#262626}

<h1 style="color: #fff">Hamiltonian Monte Carlo</h1>

<center>
```{r, echo=FALSE, out.width='75%'}
knitr::include_graphics("files/HMC.png")
```
</center>

## HMC in 3 steps:

> 1) update $\phi$, sampled from $\phi \sim \mathcal{N}(0, I)$    
> 2) simultaneously updating of $(\theta,\phi)$ via leapfrog steps    
> 3) acceptance/ rejection step analog to MH-Algorithm    

<div class="fragment">

### Ingredients

* (un-normalized) posterior density $p(\theta|y)$    
</div>

<div class="fragment">
* gradient of $log_e(p(\theta|y))$: 
$\frac{\partial log_e(p(\theta|y))}{\partial \theta}$  
(Note: use analytic solutions here if possible, numerical might make the computational benefit vanish)
</div>

<div class="fragment">
* the momentum distribution $p(\phi)$  
$\rightarrow$ usually $\phi \sim \mathcal{N_d}(0, I)$ where 0 denotes a zero vector of $\mathbb{R^d}$ and I denotes a $\mathbb{R^{dxd}}$ identity matrix
</div>

## Intuition of Leapfrogsteps

> * Think of 3D density curvature  

> * preserving the posterior for $\lim_{e \to 0} p(\theta,\phi|y)$

<div class="fragment">
* Suppose HMC moves towards *low posterior density regions*:


$$
sgn\Big(\frac{dlog_e(p(\theta|y))}{d\theta}\Big) = -1 \ \Rightarrow \ \phi\ decreases
$$
</div>

<div class="fragment">

* Suppose HMC moves towards *a local posterior maximum*:

$$
\frac{dlog_e(p(\theta|y))}{d\theta} = 0 \ \Rightarrow \ p(\theta|y)\ slows \ by\ moving\ closer\ to\ local\ max
$$
</div>

<div class="fragment">
$\rightarrow$ HMC works like a mode-finder
</div>

## Phylical analogy

<center>
```{r, echo=FALSE, out.width='75%'}
knitr::include_graphics("files/halfpipe.gif")
```
</center>

## Phylical analogy - Why use log?

<center>
```{r, echo=FALSE, out.width='75%'}
knitr::include_graphics("files/log_gradient.gif")
```
</center>

## Code - Parameter

```{r, code=readLines("../R/Hamiltonian_MonteCarlo.R")[c(1:9, 42)]}
```


## Code - initilaize Values

```{r, code=readLines("../R/Hamiltonian_MonteCarlo.R")[c(1:14, 42)]}
```

## Code - HMC iteration

```{r, code=readLines("../R/Hamiltonian_MonteCarlo.R")[c(1:21, 40, 42)]}
```

## Code - Leapfrogsteps

```{r, code=readLines("../R/Hamiltonian_MonteCarlo.R")[c(1:30, 40, 42)]}
```

## Code - Accept & Return

```{r, code=readLines("../R/Hamiltonian_MonteCarlo.R")}
```

## {data-background="files/HMC_problem.gif"} 
Problem
@feng20

> * taking too few or too large steps $\rightarrow \ \theta^t\ \& \ \theta^{t+1}$ end up very close. 

## (Hand-)Tuning Parameters

> $\epsilon = stepsize$  
> $\mathcal{L} = \#Leapfrogsteps$  
> $\phi = momentum$  

<div class="fragment">
But how?

<center>
```{r, echo=FALSE, out.width='50%'}
knitr::include_graphics("files/halfpipe.gif")
```
</center>
</div>

## Setting the tuning parameters

<div class="fragment">
* *Radius*:
  
  stay in the radius of you target distribution. Rule of thumb: $\epsilon \mathcal{L} = 1$
</div>

<div class="fragment">
* *adaptive updating*: 

  1) run $M_{init}$ steps with initial setting

  2) adjust the parameters based on knowledge from previous run and rerun the model for $M_{adjust}$ steps
</div>

<div class="fragment">
* *Acceptance Sweet Spot*: 65% acceptance rate ($\alpha$)
  
  if $\alpha < 0.65 \Rightarrow$ leapfrog jumps are too ambitious.
  Set $\mathcal{L}\uparrow, \epsilon \downarrow$.
  
  if $\alpha > 0.65 \Rightarrow$ leapfrog jumps are too cautious.
  Set $\mathcal{L}  \downarrow, \epsilon \uparrow$.
(see @gelman13)
</div>

## Desirable behavoir for tuning parameters tuning parameters HMC:

> 1) $\mathcal{L}$ driving the trajectory of steps in one iteration though the whole posterior space.  
*Tackeled by NUTS*

> 2) $\epsilon$ getting smaller in areas of high curvature exploiting various areas.  
*Tackeled by dual averaging*

> 3) $Covar(\phi)$ scaling to the local curvature.  
*Riemanian Integral*

<div class="fragment">
$\rightarrow$ All three approaches may be combined. In the following we will discuss the implementation for a No-U-Turn sampler with dual averaging, as discussed in Gelman and Hoffman (2014).@hoffman2014
</div>

# {data-background=#262626}

<h1 style="color: #fff" class="r-fit-text">The (naive) No-U-Turn Sampler</h1>

<center>
```{r, echo=FALSE}
knitr::include_graphics("files/nNUTS.png")
```
</center>

<!--
NOTES:
> * As we use the information from Hamiltonian dynamics to tune $\epsilon$ and $\mathcal{L}$ within the run iteration don't guarantee convergence anymore

> * Property of markov chain is not given anymore

<div class="fragment">
* What do we do now?

  + Derive a heuristic when we want to stop the sampling
  + Ensure the adaption satisfies the Markov Chain properties
</div>
-->

## Heuristic Stopping Criteria

</small>

* Lets look at one iteration $t$ in HMC where we intentionally set
  a) $\mathcal{L_t}$ to small
  b) $\mathcal{L_t}$ to high

* The $\mathcal{L_t}$-Leapfrog steps performed from starting state $q_{right} = (\theta_{right}, r_{right})$ in phase-space to their end after  might look as follows $\mathcal{L_t}$ Leapfrogsteps $q_{left} = (\theta_{left}, r_{left})$ 

```{r, echo=FALSE}
lable1 <- "Left Plot: Expanding the trajectory in either direction typically extends the trajectory further  across the energy level set (grey) towards unexplored neighborhood. Right Plot: Further expansion typically contracts the boundaries of the trajectory towards each other and neighborhoods that have already been explored."
```

<center>
```{r, echo=FALSE, fig.cap=lable1, out.width="50%"}
knitr::include_graphics("files/U-Turn-Criteria.png")
```
</center>
</small>

## Criterion

$\rightarrow$ explore the energy level stepwise @betancourt2017

$$
r_{left} (\theta_{right} - \theta_{left}) < 0\\
r_{right} (\theta_{left} - \theta_{right}) < 0
$$

> *Derivation:* this is basically a euclidean derivative w.r.t. time t of half the squared distance between two positions: $\frac{d(\theta_1 - \theta_2)}{dt}$.

> *Intuition:* this is the dot product of the two vectors from the picture.
If the dot product gets higher than 0, the trajectory will make a *u-turn*.
This is when we "traveled maximally" in phase space an so where we want to stop exploring the enery set.

## Naive Stepwise Exploration Scheme

> 1) Build a trajectory with a given length
> 2) Check the Termination (No-U-Turn) Criterion
> 3) Expand the trajectory and & Repeat Checks
> 4) Return the sample once the criterion is met

> Naive Additive Scheme: Check the termination Criteria for each and every point between any two points
Smart Multiplicative Scheme: Double the trajectory to the old trajectory and so create a balanced binary tree. Compare the criterion only between subtrees.

## Doubling- expand the trajectory

```{r, echo=FALSE}
lable2 <- "Typical doubling proccedure. The initial point is black. Each colour desricbes a new subtree."
```

<center>
```{r, echo=FALSE, fig.cap=lable2, out.width="75%"}
knitr::include_graphics("files/Doubling.png")
```
</center>

@hoffman2014
The doubling is halted when the sub-trajectories from the leftmost to the rightmost nodes of any balanced binary tree start to double back on themselves.

*Info:* We have to double fore- and backwards in our trajectory to guarantee reversibility in time
*Problem*: this naive scheme still violates the reversibility criteria

## Slice to the Rescue

Some of the trajectory points sampled have to be condemn because they exhibit pathological behavior.
To determine those points we introduce a slice variable $u$ to our posterior, such that
$p(u|\theta,r) = Unif(u; [0, e^{\mathcal{L}(\theta) - \frac{1}{2} <r,r>}])$, where $p(\theta, r) \propto \mathcal{L}(\theta) - \frac{1}{2} <r,r>$ is the log-joint distribution of $\theta$ an $r$.

$p(u, \theta,r) \propto \mathbb{I}[u \in [0, e^{p(\theta, r)}]]$

*Alternative:* draw multinomial over states in the trajectory 

## $\mathcal{B}, \mathcal{C}$ in NUTS


$\mathcal{B}$: constituted by all leaves of the binary tree generated in the doubling proccedure of one NUTS iteration.
If $j$ denotes the depth of a tree the amount of visited states through doubling in leapfrog trajectory is $\#\mathcal{B} = 2^j$.  
$\mathcal{C}$: contains all valid states visited.

```{r, echo=FALSE}
lable3 <- "Example of a trajectory generated during one iteration of NUTS."
```

<center>
```{r, echo=FALSE, fig.cap=lable3, out.width="50%"}
knitr::include_graphics("files/trajectory.png")
```
</center>

## Implement NUTS - Initialize

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_naive_NUTS.R")[c(1:15, 76)]}
```

## Implement NUTS - Itertation

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_naive_NUTS.R")[c(1:31, 74, 76)]}
```

## Implement NUTS - Doubling the tree

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_naive_NUTS.R")[c(1:63, 74, 76)]}
```

## Implement NUTS - Sample a state

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_naive_NUTS.R")}
```

## Implement Build Trees - Initialize

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_Build_Tree.R")[c(1:20, 68)]}
```

## Implement Build Trees - Base Case

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_Build_Tree.R")[c(1:28, 51, 68)]}
```

## Implement Build Leaf

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_Build_Tree.R")[70:104]}
```

## Implement Build Trees - Doubled Recurion

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_Build_Tree.R")[c(1:51, 67, 68)]}
```

## Implement Build Trees - Update State

```{r, warning=FALSE, code=readLines("../R/Showcase_Functions/Simplified_Build_Tree.R")[c(1:68)]}
```


# {data-background=#262626}

<h1 style="color: #fff" class="r-fit-text">No-U-Turn Sampler with dual averaging</h1>

```{r, echo=FALSE}
knitr::include_graphics("files/NUTS.png")
```

# References
